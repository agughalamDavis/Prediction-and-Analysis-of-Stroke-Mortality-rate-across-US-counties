{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import math\n",
    "import csv\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "from pymongo import MongoClient\n",
    "from pprint  import pprint\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#Linear regression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# decision tree. import the regressor \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "#function to connect to mongo db and create database stroke\n",
    "def mongo(db_name):\n",
    "    #connect to mongodb\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "    #create database dap\n",
    "    db = client[db_name]\n",
    "    \n",
    "    return db\n",
    "\n",
    "#function to read dataset from web and prepare for mongo db insert. It takes the path as argument\n",
    "def get_dataset(url):\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    json_data = json.loads(data)\n",
    "    meta_data = json_data['meta']\n",
    "    main_data = json_data['data']\n",
    "\n",
    "    df = pd.DataFrame(meta_data)\n",
    "    meta_data['view']['columns']\n",
    "    headers = []\n",
    "    for item in meta_data['view']['columns']:\n",
    "        headers.append(item['fieldName'])\n",
    "\n",
    "    #prepare data for insert\n",
    "    all_rows = []\n",
    "    for j in range(len(main_data)):\n",
    "        row = {}\n",
    "        for i in range(len(headers)):\n",
    "            row[headers[i]] = main_data[j][i]\n",
    "        all_rows.append(row)\n",
    "        \n",
    "    return all_rows\n",
    "\n",
    "#function to create table and insert. Takes two arguments, what is to be inserted and table name\n",
    "def insert_to_mongo(table, data):\n",
    "    \n",
    "    #create table \n",
    "    mongo_object = db[table]\n",
    "\n",
    "    #insert data into created table\n",
    "    result = mongo_object.insert_many(data)\n",
    "    \n",
    "#function to read file\n",
    "def read_file(file_path):\n",
    "    states = []\n",
    "    with open(file_path) as f:\n",
    "        csv_data = csv.reader(f)\n",
    "        for row in csv_data:\n",
    "            states.append(row)\n",
    "\n",
    "    #convert to pandas dataframe\n",
    "    df_states = pd.DataFrame(states)\n",
    "    df_states.columns = df_states.iloc[0]\n",
    "    df_states = df_states.drop(df_states.index[0])\n",
    "    \n",
    "    return df_states\n",
    "\n",
    "#function to fetch stroke data from mongo db\n",
    "def mongo_fetch_stroke(df_states):\n",
    "    \n",
    "    #fetch stroke mortality rate from mongo db\n",
    "    stroke = db.stroke\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    stroke_from_mongo = stroke.find({'stratification1':'Overall','stratification2':'Overall','geographiclevel':'County'})\n",
    "\n",
    "    stroke_data = []\n",
    "    for row in stroke_from_mongo:\n",
    "        stroke_data.append(row)\n",
    "\n",
    "    #store fetched data as pandas dataframe\n",
    "    df_stroke = pd.DataFrame(stroke_data)\n",
    "    \n",
    "    #data preprocessing for stroke mortality rate dataset\n",
    "\n",
    "    #drop unneccesary columns\n",
    "    drop_col = [':@computed_region_bxsw_vy29', ':@computed_region_he4y_prf8',\n",
    "           ':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id', 'class',\n",
    "           'data_value_footnote', 'data_value_footnote_symbol', 'data_value_type',\n",
    "            'datasource', 'geocoded_column',\n",
    "            'stratificationcategory1', 'stratificationcategory2',\n",
    "           'topic', 'topicid', 'x_lon', 'y_lat']\n",
    "    df_stroke = df_stroke.drop(drop_col, axis=1)\n",
    "\n",
    "    #rename required columns\n",
    "    df_stroke = df_stroke.rename(columns = {\n",
    "        'locationabbr':'State',\n",
    "        'locationdesc':'County',\n",
    "        'data_value' : 'Stroke_mortality_rate',\n",
    "        'data_value_unit':'Unit'\n",
    "    })\n",
    "\n",
    "    #strip county and city from the column county\n",
    "    df_stroke['County'] = df_stroke['County'].map(lambda x: x.rstrip('CountyCi'))\n",
    "\n",
    "    #merge stroke data with states data to get proper state names and not abbreviation only\n",
    "    df_stroke = pd.merge(df_stroke, df_states, on = 'State', how=\"inner\")\n",
    "\n",
    "    #concatenate state and county to make sure they are unique\n",
    "    df_stroke['StateCounty'] = df_stroke['City'].str.cat(df_stroke['County'], sep =\" \")\n",
    "    \n",
    "    #strip trailing white spaces from the statecounty column in df_stroke\n",
    "    df_stroke['StateCounty'] = df_stroke['StateCounty'].map(lambda x: x.rstrip(' '))\n",
    "    \n",
    "    return df_stroke\n",
    "\n",
    "#function to fetch drug data from mongo\n",
    "def mongo_fetch_drug():\n",
    "    \n",
    "    #fetch drug poisoning data from mongo db\n",
    "    drug_poisoning = db.drug_poisoning\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    drug_from_mongo = drug_poisoning.find({'year':'2015'})\n",
    "\n",
    "    drug_data = []\n",
    "    for row in drug_from_mongo:\n",
    "        drug_data.append(row)\n",
    "\n",
    "    #convert to pandas dataframe\n",
    "    df_drug = pd.DataFrame(drug_data)\n",
    "    \n",
    "    #data preprocessing for drug poisoning data set\n",
    "\n",
    "    #drop unnecessary columns\n",
    "    drop_col = [':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id',\n",
    "           'estimated_age_adjusted_death_rate_11_categories_in_ranges', 'fips',\n",
    "           'fips_state','year']\n",
    "    df_drug = df_drug.drop(drop_col, axis=1)\n",
    "\n",
    "    #strip county and city from the column county\n",
    "    df_drug['county'] = df_drug['county'].map(lambda x: x[:-11])\n",
    "\n",
    "    #concatenate state and county to make sure they are unique\n",
    "    df_drug['StateCounty'] = df_drug['state'].str.cat(df_drug['county'], sep =\" \")\n",
    "    \n",
    "    \n",
    "    return df_drug\n",
    "\n",
    "#function to fetch and process heart data from mong\n",
    "def mongo_fetch_heart(df_states):\n",
    "    #fetch heart disease data from mongo db\n",
    "    heart_disease = db.heart_disease\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    heart_from_mongo = heart_disease.find({'stratification1':'Overall','stratification2':'Overall','geographiclevel':'County'})\n",
    "\n",
    "    heart_data = []\n",
    "    for row in heart_from_mongo:\n",
    "        heart_data.append(row)\n",
    "\n",
    "    #convert to pandas dataframe\n",
    "    df_heart = pd.DataFrame(heart_data)\n",
    "    \n",
    "    #data processing for the heart disease data set\n",
    "    #drop unneccesary columns\n",
    "    drop_col = [':@computed_region_bxsw_vy29', ':@computed_region_he4y_prf8',\n",
    "           ':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id', 'class',\n",
    "           'data_value_footnote', 'data_value_footnote_symbol', 'data_value_type',\n",
    "         'datasource', 'geocoded_column', 'geographiclevel',\n",
    "            'locationid', 'stratification1',\n",
    "           'stratification2', 'stratificationcategory1', 'stratificationcategory2',\n",
    "           'topic', 'topicid', 'x_lon', 'y_lat', 'year']\n",
    "    df_heart = df_heart.drop(drop_col, axis=1)\n",
    "\n",
    "    #rename required columns\n",
    "    df_heart = df_heart.rename(columns = {\n",
    "        'locationabbr':'State',\n",
    "        'locationdesc':'County',\n",
    "        'data_value' : 'heart_disease_mortality_rate',\n",
    "        'data_value_unit':'Unit'\n",
    "    })\n",
    "\n",
    "    #strip county and city from the column county\n",
    "    df_heart['County'] = df_heart['County'].map(lambda x: x.rstrip('CountyCi'))\n",
    "\n",
    "    #merge heart disease data with states data to get proper state names and not abbreviation only\n",
    "    df_heart = pd.merge(df_heart, df_states, on = 'State', how=\"inner\")\n",
    "\n",
    "    #concatenate state and county to make sure they are unique\n",
    "    df_heart['StateCounty'] = df_heart['City'].str.cat(df_heart['County'], sep =\" \")\n",
    "    \n",
    "    #strip trailing white spaces from the statecounty column in df_stroke\n",
    "    df_heart['StateCounty'] = df_heart['StateCounty'].map(lambda x: x.rstrip(' '))\n",
    "    \n",
    "    return df_heart\n",
    "\n",
    "#fetch teen birth data from mongo db\n",
    "def mongo_fetch_teen():\n",
    "   \n",
    "    teen_birth = db.teen_birth_rate\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    teen_from_mongo = teen_birth.find({'year':'2015'})\n",
    "\n",
    "    teen_data = []\n",
    "    for row in teen_from_mongo:\n",
    "        teen_data.append(row)\n",
    "\n",
    "    #convert to pandas dataframe\n",
    "    df_teen = pd.DataFrame(teen_data)\n",
    "    \n",
    "    #data processing for the teen birth data set\n",
    "    #drop unneccesary columns\n",
    "    drop_col = [':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id',\n",
    "           'combined_fips_code', 'county_fips_code',\n",
    "         'state_fips_code',\n",
    "            'year']\n",
    "    df_teen = df_teen.drop(drop_col, axis=1)\n",
    "\n",
    "    #concatenate state and county to make sure they are unique\n",
    "    df_teen['StateCounty'] = df_teen['state'].str.cat(df_teen['county'], sep =\" \")\n",
    "\n",
    "    return df_teen\n",
    "\n",
    "#preliminary explorations\n",
    "#fetch stroke mortality rate for females from mongo db\n",
    "def mongo_fetch_female():\n",
    "    \n",
    "    female_stroke = db.stroke\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    female_stroke_from_mongo = female_stroke.find({'stratification1':'Female','stratification2':'Overall','geographiclevel':'County'})\n",
    "\n",
    "    female_stroke_data = []\n",
    "    for row in female_stroke_from_mongo:\n",
    "        female_stroke_data.append(row)\n",
    "\n",
    "    #store fetched data as pandas dataframe\n",
    "    df_female_stroke = pd.DataFrame(female_stroke_data)\n",
    "    \n",
    "    #drop unneccesary columns\n",
    "    drop_col = [':@computed_region_bxsw_vy29', ':@computed_region_he4y_prf8',\n",
    "           ':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id', 'class',\n",
    "           'data_value_footnote', 'data_value_footnote_symbol', 'data_value_type'\n",
    "           , 'datasource', 'geocoded_column', 'geographiclevel', 'locationid'\n",
    "           , 'stratificationcategory1', 'stratificationcategory2',\n",
    "           'topic', 'topicid', 'x_lon', 'y_lat', 'year']\n",
    "\n",
    "    df_female_stroke = df_female_stroke.drop(drop_col, axis=1)\n",
    "\n",
    "    #rename required columns\n",
    "    df_female_stroke = df_female_stroke.rename(columns = {\n",
    "        'locationabbr':'State',\n",
    "        'locationdesc':'County',\n",
    "        'data_value' : 'Female_Stroke_mortality_rate',\n",
    "        'data_value_unit':'Unit'\n",
    "    })\n",
    "    \n",
    "    df_female_stroke['Female_Stroke_mortality_rate'] = pd.to_numeric(df_female_stroke['Female_Stroke_mortality_rate'])\n",
    "    \n",
    "    return df_female_stroke\n",
    "\n",
    "#fetch stroke mortality rate for males from mongo db\n",
    "def mongo_fetch_male():\n",
    "    \n",
    "    male_stroke = db.stroke\n",
    "\n",
    "    #fetch required data from mongodb\n",
    "    male_stroke_from_mongo = male_stroke.find({'stratification1':'Male','stratification2':'Overall','geographiclevel':'County'})\n",
    "\n",
    "    male_stroke_data = []\n",
    "    for row in male_stroke_from_mongo:\n",
    "        male_stroke_data.append(row)\n",
    "\n",
    "    #store fetched data as pandas dataframe\n",
    "    df_male_stroke = pd.DataFrame(male_stroke_data)\n",
    "    \n",
    "    #drop unneccesary columns\n",
    "    drop_col = [':@computed_region_bxsw_vy29', ':@computed_region_he4y_prf8',\n",
    "           ':created_at', ':created_meta', ':id', ':meta', ':position', ':sid',\n",
    "           ':updated_at', ':updated_meta', '_id', 'class',\n",
    "           'data_value_footnote', 'data_value_footnote_symbol', 'data_value_type'\n",
    "           , 'datasource', 'geocoded_column', 'geographiclevel', 'locationid'\n",
    "           , 'stratificationcategory1', 'stratificationcategory2',\n",
    "           'topic', 'topicid', 'x_lon', 'y_lat', 'year']\n",
    "\n",
    "    df_male_stroke = df_male_stroke.drop(drop_col, axis=1)\n",
    "\n",
    "    #rename required columns\n",
    "    df_male_stroke = df_male_stroke.rename(columns = {\n",
    "        'locationabbr':'State',\n",
    "        'locationdesc':'County',\n",
    "        'data_value' : 'Male_Stroke_mortality_rate',\n",
    "        'data_value_unit':'Unit'\n",
    "    })\n",
    "    \n",
    "    df_male_stroke['Male_Stroke_mortality_rate']= pd.to_numeric(df_male_stroke['Male_Stroke_mortality_rate'])\n",
    "    \n",
    "    return df_male_stroke\n",
    "\n",
    "#sort both dataframes in descending order and select\n",
    "def top(n):\n",
    "    \n",
    "    df_female_top = pd.DataFrame(df_female_stroke.sort_values('Female_Stroke_mortality_rate', ascending=False).head(n))\n",
    "    df_male_top = pd.DataFrame(df_male_stroke.sort_values('Male_Stroke_mortality_rate', ascending=False).head(n))\n",
    "    \n",
    "    print('The mean stroke mortality rate for male is : ' + str(df_male_stroke['Male_Stroke_mortality_rate'].mean()))\n",
    "    print('The mean stroke mortality rate for female is : '  + str(df_female_stroke['Female_Stroke_mortality_rate'].mean()))\n",
    "    \n",
    "    return df_female_top, df_male_top\n",
    "    \n",
    "    \n",
    "#plot stroke mortality rates for males and females across the counties to know which is higher for selected\n",
    "def plot_top():\n",
    "    \n",
    "    female = list(df_female_top['Female_Stroke_mortality_rate'])\n",
    "    male = list(df_male_top['Male_Stroke_mortality_rate'])\n",
    "    names = list(df_male_top['County'])\n",
    "    fig = go.Figure(data=[\n",
    "\n",
    "    go.Bar(name='Male', x=names, y=male, width = 0.2),\n",
    "    go.Bar(name='Female', x=names, y=female, width = 0.4),\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title=\"Top 10 stroke mortality rates for males and females\",\n",
    "    xaxis_title=\"County\",\n",
    "    yaxis_title=\"Stroke mortality rate\",\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "#merge clean datasets\n",
    "def merger():\n",
    "    #merge df_stroke, df_drug, on StateCounty\n",
    "    df_stroke_drug= pd.merge(df_stroke, df_drug, on = 'StateCounty', how=\"inner\")\n",
    "    \n",
    "    #merge resulting data frame with df_heart\n",
    "    df_stroke_drug_heart= pd.merge(df_stroke_drug, df_heart, on = 'StateCounty', how=\"inner\")\n",
    "    \n",
    "    #merge resulting dataframe with df_teen\n",
    "    df = pd.merge(df_stroke_drug_heart, df_teen, on = 'StateCounty', how=\"inner\")\n",
    "    \n",
    "    #drop some columns from final dataset\n",
    "    drop_col = ['Unit_x', 'State_x', 'locationid', 'stratification1', 'stratification2', 'year',\n",
    "           'Latitude_x', 'Longitude_x', 'City_x', 'StateCounty', 'county_x',\n",
    "            'st', 'state_x', 'Unit_y',\n",
    "           'State_y', 'County_y', 'Latitude_y', 'Longitude_y',\n",
    "            'county_y', 'state_y',]\n",
    "    df = df.drop(drop_col, axis=1)\n",
    "\n",
    "    #rename required columns in final dataset\n",
    "    df = df.rename(columns = {\n",
    "        'County_x':'County',\n",
    "        'City_y':'State',\n",
    "        'lower_confidence_limit' : 'birth_rate_lower_limit',\n",
    "        'upper_confidence_limit':'birth_rate_upper_limit'\n",
    "    })\n",
    "    \n",
    "    #convert all numeric data to appropriate data types\n",
    "    df['Stroke_mortality_rate'] = pd.to_numeric(df['Stroke_mortality_rate'])\n",
    "    df['population'] = pd.to_numeric(df['population'])\n",
    "    df['heart_disease_mortality_rate'] = pd.to_numeric(df['heart_disease_mortality_rate'])\n",
    "    df['birth_rate'] = pd.to_numeric(df['birth_rate'])\n",
    "    df['birth_rate_lower_limit'] = pd.to_numeric(df['birth_rate_lower_limit'])\n",
    "    df['birth_rate_upper_limit'] = pd.to_numeric(df['birth_rate_upper_limit'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "#insert into postgres\n",
    "def postgres_insert():\n",
    "    #connect to postgres and create database stroke\n",
    "    import psycopg2\n",
    "    try:\n",
    "        dbConnection = psycopg2.connect(\n",
    "        user = \"dap\",\n",
    "        password = \"dap\",\n",
    "        host = \"192.168.56.30\",\n",
    "        port = \"5432\",\n",
    "        database = \"postgres\")\n",
    "        dbConnection.set_isolation_level(0) # AUTOCOMMIT\n",
    "        dbCursor = dbConnection.cursor()\n",
    "        dbCursor.execute('CREATE DATABASE stroke_d;')\n",
    "        dbCursor.close()\n",
    "    except (Exception , psycopg2.Error) as dbError :\n",
    "        print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "    finally:\n",
    "        if(dbConnection): dbConnection.close()\n",
    "            \n",
    "    #insert data frame into table stroke in postgres\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('postgresql://dap:dap@192.168.56.30:5432/stroke_d')\n",
    "    df.to_sql('stroke_d', engine)\n",
    "    \n",
    "\n",
    "#fetch from postgres\n",
    "def postgres_fetch():\n",
    "    sql = \"SELECT * FROM stroke_d;\"\n",
    "    try:\n",
    "        dbConnection = psycopg2.connect(\n",
    "        user = \"dap\",\n",
    "        password = \"dap\",\n",
    "        host = \"192.168.56.30\",\n",
    "        port = \"5432\",\n",
    "        database = \"stroke_d\")\n",
    "        stroke_dataframe = sqlio.read_sql_query(sql, dbConnection)\n",
    "    except (Exception , psycopg2.Error) as dbError :\n",
    "        print (\"Error:\", dbError)\n",
    "    finally:\n",
    "        if(dbConnection): dbConnection.close()\n",
    "            \n",
    "    return stroke_dataframe\n",
    "\n",
    "\n",
    "#stroke mortality rate by state bar plot\n",
    "def stroke_by_state_plot():\n",
    "    \n",
    "    df_states_top = pd.DataFrame(states_stroke.sort_values('Stroke_mortality_rate', ascending=False).head(10))\n",
    "   \n",
    "    colors = ['crimson',] * 10\n",
    "    colors[0] = 'green'\n",
    "    stroke_mortality_rate = df_states_top['Stroke_mortality_rate']\n",
    "    states = df_states_top['State']\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "    x=list(states),\n",
    "    y=list(stroke_mortality_rate),\n",
    "    marker_color=colors\n",
    "    )])\n",
    "    fig.update_layout(title_text='Stroke Mortality Rate by State (TOP 10)')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "#stroke mortality rate by county bar plot\n",
    "def stroke_by_county_plot():\n",
    "    df_stroke_top = pd.DataFrame(stroke_dataframe.sort_values('Stroke_mortality_rate', ascending=False).head(10))\n",
    "    colors = ['blue',] * 10\n",
    "    colors[0] = 'red'\n",
    "    stroke_mortality_rate = df_stroke_top['Stroke_mortality_rate']\n",
    "    counties = df_stroke_top['County']\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "    x=list(counties),\n",
    "    y=list(stroke_mortality_rate),\n",
    "    marker_color=colors\n",
    "    )])\n",
    "    fig.update_layout(title_text='Stroke Mortality Rate by County (TOP 10)')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "#teen birth rate by county plot\n",
    "def birth_by_county_plot():\n",
    "    df_birth_top = pd.DataFrame(stroke_dataframe.sort_values('birth_rate', ascending=False).head(10))\n",
    "    #teen birth rate by county bar plot\n",
    "    colors = ['brown',] * 10\n",
    "    colors[0] = 'green'\n",
    "    birth_rate = df_birth_top['birth_rate']\n",
    "    counties = df_birth_top['County']\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "    x=list(counties),\n",
    "    y=list(birth_rate),\n",
    "    marker_color=colors\n",
    "    )])\n",
    "    fig.update_layout(title_text='Birth Rate by County (TOP 10)')\n",
    "    fig.show()\n",
    "\n",
    "def pop_by_county_plot():\n",
    "    #population by county bar plot\n",
    "    df_pop_top = pd.DataFrame(stroke_dataframe.sort_values('population', ascending=False).head(10))\n",
    "    colors = ['purple',] * 10\n",
    "    colors[0] = 'yellow'\n",
    "    population = df_pop_top['population']\n",
    "    counties = df_pop_top['County']\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "    x=list(counties),\n",
    "    y=list(population),\n",
    "    marker_color=colors\n",
    "    )])\n",
    "    fig.update_layout(title_text='Population by County (TOP 10)')\n",
    "    fig.show()\n",
    "\n",
    "def plot_distribution():\n",
    "    #histogram showing distribution of stroke mortality rate\n",
    "    fig = px.histogram(stroke_dataframe,\n",
    "    x=\"Stroke_mortality_rate\")\n",
    "    fig.update_layout(title_text='Histogram of stroke mortality rate distribution')\n",
    "    fig.show()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(y=stroke_dataframe['Stroke_mortality_rate'], name='Stroke Mortality Rate',\n",
    "    marker_color = 'indianred'))\n",
    "    fig.update_layout(title_text='Boxplot of stroke mortality rate distribution')\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "def bubble_plot():\n",
    "    #scatter plot showing the relationship between stroke mortality rate, population, birth rate and heart disease mortality rate\n",
    "    fig = px.scatter(stroke_dataframe,\n",
    "    x=\"heart_disease_mortality_rate\",\n",
    "    y=\"Stroke_mortality_rate\",\n",
    "    color=\"birth_rate\",\n",
    "    size='population')\n",
    "    \n",
    "    fig.update_layout(title_text='Bubble plot showing relationship of variables')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def scatters():\n",
    "    #scatter plot showing the relationship between stroke mortality rate, population\n",
    "    fig = px.scatter(stroke_dataframe,\n",
    "    x=\"population\",\n",
    "    y=\"Stroke_mortality_rate\")\n",
    "    fig.update_layout(title_text='Scatter plot between stroke mortality rate and population')\n",
    "    fig.show()\n",
    "    \n",
    "    #scatter plot showing the relationship between stroke mortality rate and birth rate\n",
    "    fig = px.scatter(stroke_dataframe,\n",
    "    x=\"birth_rate\",\n",
    "    y=\"Stroke_mortality_rate\")\n",
    "    fig.update_layout(title_text='Scatter plot between stroke mortality rate and birth rate')\n",
    "    fig.show()\n",
    "    \n",
    "    #scatter plot showing the relationship between stroke mortality rate and heart disease mortality rate\n",
    "    fig = px.scatter(stroke_dataframe,\n",
    "    x=\"heart_disease_mortality_rate\",\n",
    "    y=\"Stroke_mortality_rate\")\n",
    "    fig.update_layout(title_text='Scatter plot between stroke mortality rate and heart disease')\n",
    "    fig.show()\n",
    "\n",
    "def transformer():\n",
    "    #convert stroke mortality rate column to log in attempt to fix normality\n",
    "    stroke_dataframe['log_stroke'] = np.log(stroke_dataframe['Stroke_mortality_rate'])/np.log(10)\n",
    "    \n",
    "    #remove outliers more than 2.4 standard deviations away from the mean.\n",
    "    new_dataframe = stroke_dataframe[((stroke_dataframe.log_stroke - stroke_dataframe.log_stroke.mean()) / stroke_dataframe.log_stroke.std()).abs() < 2.4]\n",
    "    \n",
    "    #fill up missing value with mean\n",
    "    stroke_dataframe['log_stroke'] = stroke_dataframe['log_stroke'].fillna(stroke_dataframe['log_stroke'].mean())\n",
    "\n",
    "    #fill up missing value with mean\n",
    "    stroke_dataframe['Stroke_mortality_rate'] = stroke_dataframe['Stroke_mortality_rate'].fillna(stroke_dataframe['Stroke_mortality_rate'].mean())\n",
    "    \n",
    "    #histogram showing distribution of stroke mortality rate\n",
    "    fig = px.histogram(stroke_dataframe,\n",
    "    x=\"log_stroke\")\n",
    "    fig.update_layout(title_text='Histogram showing distribution of log transformed stroke mortality rate')\n",
    "    fig.show()\n",
    "    \n",
    "    #box plot showing distribution of log transformed stroke mortality rate\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(y=stroke_dataframe['log_stroke'],\n",
    "    marker_color = 'indianred'))\n",
    "    fig.update_layout(title_text='Box plot showing distribution of log transformed stroke mortality rate')\n",
    "    fig.show()\n",
    "    \n",
    "    #box plot showing distribution of log transformed stroke mortality rate with outliers removed\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(y=new_dataframe['log_stroke'], \n",
    "    marker_color = 'indianred'))\n",
    "    fig.update_layout(title_text='Box plot showing distribution of log transformed stroke mortality rate without outliers ')\n",
    "    fig.show()\n",
    "    \n",
    "    return new_dataframe, stroke_dataframe\n",
    "\n",
    "def linear(stroke_dataframe, dependent):\n",
    "    #select data for model\n",
    "    X = stroke_dataframe[['population','heart_disease_mortality_rate','birth_rate']]\n",
    "    y = stroke_dataframe[dependent]\n",
    "\n",
    "    #split data into test and train datasets\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,train_size = .7)\n",
    "    \n",
    "    #build linear model with sklearn\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    #view coefficients\n",
    "    model.coef_\n",
    "\n",
    "    #view intercept\n",
    "    model.intercept_\n",
    "    \n",
    "    #predict values \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #check MSE\n",
    "    MSE = mean_squared_error(Y_test, y_pred)\n",
    "    \n",
    "    #check r squared\n",
    "    from sklearn.metrics import r2_score\n",
    "    rsquared = r2_score(Y_test,y_pred)\n",
    "    \n",
    "    print('The coefficients of the model are : ' + str(model.coef_))\n",
    "    print('The intercept of the model is: ' + str(model.intercept_))\n",
    "    print('The MSE of the model is : ' + str(MSE))\n",
    "    print('The rsquared of the model is: '+ str(rsquared))\n",
    "    \n",
    "    \n",
    "    df_pred = pd.DataFrame({'Actual': Y_test, 'Predicted': y_pred})\n",
    "    print(df_pred.head(10))\n",
    "    \n",
    "    actual_data = list(df_pred.head(10)['Actual'])\n",
    "    predicted_data = list(df_pred.head(10)['Predicted'])\n",
    "    names = []\n",
    "    name = list(range(len(df_pred.head(10))))\n",
    "    for item in name:\n",
    "        names.append('Datapoint ' + str(item))\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "\n",
    "    go.Bar(name='Actual', x=names, y=actual_data, width = 0.2),\n",
    "    go.Bar(name='Predicted', x=names, y=predicted_data, width = 0.4),\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "    title=\"Actual VS Predicted values for stroke mortality rates\",\n",
    "    xaxis_title=\"Data points\",\n",
    "    yaxis_title=\"Values\",\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return model.coef_, model.intercept_, y_pred, MSE, rsquared, df_pred\n",
    "\n",
    "def linear_transformed(stroke_dataframe, dependent):\n",
    "    #select data for model\n",
    "    X = stroke_dataframe[['population','heart_disease_mortality_rate','birth_rate']]\n",
    "    y = stroke_dataframe[dependent]\n",
    "\n",
    "    #split data into test and train datasets\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,train_size = .7)\n",
    "    \n",
    "    #build linear model with sklearn\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    #view coefficients\n",
    "    model.coef_\n",
    "\n",
    "    #view intercept\n",
    "    model.intercept_\n",
    "    \n",
    "    #predict values \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #check MSE\n",
    "    MSE = 10 ** mean_squared_error(Y_test, y_pred)\n",
    "    \n",
    "    #check r squared\n",
    "    from sklearn.metrics import r2_score\n",
    "    rsquared = r2_score(Y_test,y_pred)\n",
    "    \n",
    "    print('The coefficients of the model are : ' + str(model.coef_))\n",
    "    print('The intercept of the model is: ' + str(model.intercept_))\n",
    "    print('The MSE of the model is : ' + str(MSE))\n",
    "    print('The rsquared of the model is: '+ str(rsquared))\n",
    "    \n",
    "    \n",
    "    df_pred = pd.DataFrame({'Actual': 10 ** Y_test, 'Predicted': 10 ** y_pred})\n",
    "    print(df_pred.head(10))\n",
    "    \n",
    "    actual_data = list(df_pred.head(10)['Actual'])\n",
    "    predicted_data = list(df_pred.head(10)['Predicted'])\n",
    "    names = []\n",
    "    name = list(range(len(df_pred.head(10))))\n",
    "    for item in name:\n",
    "        names.append('Datapoint ' + str(item))\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "\n",
    "    go.Bar(name='Actual', x=names, y=actual_data, width = 0.2),\n",
    "    go.Bar(name='Predicted', x=names, y=predicted_data, width = 0.4),\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "    title=\"Actual VS Predicted values for stroke mortality rates\",\n",
    "    xaxis_title=\"Data points\",\n",
    "    yaxis_title=\"Values\",\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    return model.coef_, model.intercept_, y_pred, MSE, rsquared, df_pred\n",
    "\n",
    "def decision(stroke_dataframe, dependent):\n",
    "     \n",
    "    #select data for model\n",
    "    X = stroke_dataframe[['population','heart_disease_mortality_rate','birth_rate']]\n",
    "    y = stroke_dataframe[dependent]\n",
    "\n",
    "    #split data into test and train datasets\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,train_size = .7)\n",
    "\n",
    "    # create a regressor object \n",
    "    regressor = DecisionTreeRegressor(random_state = 0)  \n",
    "\n",
    "    # fit the regressor with X and Y data \n",
    "    regressor.fit(X_train, Y_train)\n",
    "    \n",
    "    #predict values with decision tree\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    \n",
    "    #check MSE for decision tree\n",
    "    MSE = mean_squared_error(Y_test, y_pred)\n",
    "    \n",
    "    df_pred = pd.DataFrame({'Actual': Y_test, 'Predicted': y_pred})\n",
    "    \n",
    "    print('The MSE of the model is : ' + str(MSE))\n",
    "    print(df_pred.head(10))\n",
    "    \n",
    "    actual_data = list(df_pred.head(10)['Actual'])\n",
    "    predicted_data = list(df_pred.head(10)['Predicted'])\n",
    "    names = []\n",
    "    name = list(range(len(df_pred.head(10))))\n",
    "    for item in name:\n",
    "        names.append('Datapoint ' + str(item))\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "\n",
    "    go.Bar(name='Actual', x=names, y=actual_data, width = 0.2),\n",
    "    go.Bar(name='Predicted', x=names, y=predicted_data, width = 0.4),\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "    title=\"Actual VS Predicted values for stroke mortality rates\",\n",
    "    xaxis_title=\"Data points\",\n",
    "    yaxis_title=\"Values\",\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    return MSE, df_pred\n",
    "\n",
    "def decision_transformed(stroke_dataframe, dependent):\n",
    "     \n",
    "    #select data for model\n",
    "    X = stroke_dataframe[['population','heart_disease_mortality_rate','birth_rate']]\n",
    "    y = stroke_dataframe[dependent]\n",
    "\n",
    "    #split data into test and train datasets\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,train_size = .7)\n",
    "\n",
    "    # create a regressor object \n",
    "    regressor = DecisionTreeRegressor(random_state = 0)  \n",
    "\n",
    "    # fit the regressor with X and Y data \n",
    "    regressor.fit(X_train, Y_train)\n",
    "    \n",
    "    #predict values with decision tree\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    \n",
    "    #check MSE for decision tree\n",
    "    MSE = 10 ** mean_squared_error(Y_test, y_pred)\n",
    "    \n",
    "    df_pred = pd.DataFrame({'Actual': 10 ** Y_test, 'Predicted': 10 ** y_pred})\n",
    "    \n",
    "    print('The MSE of the model is : ' + str(MSE))\n",
    "    print(df_pred.head(10))\n",
    "    \n",
    "    actual_data = list(df_pred.head(10)['Actual'])\n",
    "    predicted_data = list(df_pred.head(10)['Predicted'])\n",
    "    names = []\n",
    "    name = list(range(len(df_pred.head(10))))\n",
    "    for item in name:\n",
    "        names.append('Datapoint ' + str(item))\n",
    "    fig = go.Figure(data=[\n",
    "\n",
    "    go.Bar(name='Actual', x=names, y=actual_data, width = 0.2),\n",
    "    go.Bar(name='Predicted', x=names, y=predicted_data, width = 0.4),\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "    title=\"Actual VS Predicted values for stroke mortality rates\",\n",
    "    xaxis_title=\"Data points\",\n",
    "    yaxis_title=\"Values\",\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    return MSE, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main work\n",
    "#call mongo function to create mongo db database\n",
    "db = mongo('stroke')\n",
    "\n",
    "#get datasets\n",
    "paths = ['https://chronicdata.cdc.gov/views/v246-z5tb/rows.json?accessType=DOWNLOAD', \n",
    "         'https://data.cdc.gov/api/views/pbkm-d27e/rows.json?accessType=DOWNLOAD',\n",
    "        'https://chronicdata.cdc.gov/views/mfvi-hkb9/rows.json?accessType=DOWNLOAD', \n",
    "         'https://data.cdc.gov/api/views/3h58-x6cd/rows.json?accessType=DOWNLOAD']\n",
    "\n",
    "#table names to be created in mongo db\n",
    "names = ['stroke', 'drug_poisoning','heart_disease', 'teen_birth_rate']\n",
    "count = 0\n",
    "\n",
    "for url in paths:\n",
    "    #scrape data from url with get_dataset function\n",
    "    all_rows = get_dataset(url)\n",
    "    \n",
    "    #insert into mongo db\n",
    "    insert_to_mongo(names[count], all_rows)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "#read states file from drive\n",
    "df_states = read_file('statelatlong.csv')\n",
    "\n",
    "#fetch and preprocess all the data from mongo\n",
    "df_stroke = mongo_fetch_stroke(df_states)\n",
    "df_drug = mongo_fetch_drug()\n",
    "df_heart = mongo_fetch_heart(df_states)\n",
    "df_teen = mongo_fetch_teen()\n",
    "df_female_stroke = mongo_fetch_female()\n",
    "df_male_stroke =  mongo_fetch_male()\n",
    "\n",
    "#top 10 mortality rates across counties for male and female\n",
    "df_top = top(10)\n",
    "df_male_top = df_top[1]\n",
    "df_female_top = df_top[0]\n",
    "\n",
    "#plot top 10 mortality rates for male and females across the counties\n",
    "plot_top()\n",
    "\n",
    "#merge all clean datasets\n",
    "df = merger()\n",
    "\n",
    "#insert into postgres\n",
    "postgres_insert()\n",
    "\n",
    "#fetch data from postgres\n",
    "stroke_dataframe = postgres_fetch()\n",
    "stroke_dataframe = stroke_dataframe.drop('index', axis=1)\n",
    "\n",
    "#missing data heatmap\n",
    "sns.heatmap(stroke_dataframe.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "#correlation plot\n",
    "sns.heatmap(stroke_dataframe.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "#visualizations\n",
    "#states and their avevrage stroke mortality rates\n",
    "states_stroke = pd.DataFrame(stroke_dataframe.groupby('State')['Stroke_mortality_rate'].mean()).reset_index()\n",
    "stroke_by_state_plot()\n",
    "\n",
    "stroke_by_county_plot()\n",
    "\n",
    "birth_by_county_plot()\n",
    "\n",
    "pop_by_county_plot()\n",
    "\n",
    "plot_distribution()\n",
    "\n",
    "bubble_plot()\n",
    "\n",
    "scatters()\n",
    "\n",
    "#transform and visualize data column\n",
    "transformed = transformer()\n",
    "stroke_dataframe = transformed[1] #transformed dataset with outliers\n",
    "new_dataframe = transformed[0]  #transformed dataset without outliers\n",
    "\n",
    "#run linear regression without transformation and outlier removal\n",
    "print('linear regression without transformation and outlier removal results')\n",
    "linear_without_both = linear(stroke_dataframe, 'Stroke_mortality_rate')\n",
    "\n",
    "\n",
    "#run decision regression without transformation and without removal of outliers\n",
    "print('decision tree regression without transformation and without removal of outliers results')\n",
    "decision_tree_without_both = decision(stroke_dataframe, 'Stroke_mortality_rate')\n",
    "\n",
    "#run linear regression with transformation and outlier removal\n",
    "print('linear regression with transformation and outlier removal results')\n",
    "linear_with_transform = linear_transformed(stroke_dataframe, 'log_stroke')\n",
    "\n",
    "\n",
    "#run decision regression with transformation and without removal of outliers\n",
    "print('decision regression with transformation and without removal of outliers results')\n",
    "decision_tree_without_both = decision_transformed(stroke_dataframe, 'log_stroke')\n",
    "\n",
    "#run linear regression with both transformation and outlier removal\n",
    "print('linear regression with both transformation and outlier removal results')\n",
    "linear_with_both = linear_transformed(new_dataframe, 'log_stroke')\n",
    "\n",
    "#run decision regression with both transformation and removal of outliers\n",
    "print('decision tree regression with both transformation and removal of outliers results')\n",
    "decision_tree_with_both = decision_transformed(new_dataframe, 'log_stroke')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
